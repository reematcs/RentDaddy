name: Deploy to Production

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      skip_tests:
        description: 'Skip tests (emergency deployment)'
        required: false
        default: false
        type: boolean
      skip_terraform:
        description: 'Skip Terraform (app-only deployment)'
        required: false
        default: false
        type: boolean

env:
  AWS_REGION: us-east-2
  AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
  ECR_REPOSITORY_BACKEND: rentdaddy/backend
  ECR_REPOSITORY_FRONTEND: rentdaddy/frontend
  ECS_SERVICE: rentdaddy-app-service
  ECS_CLUSTER: rentdaddy-cluster
  ECS_TASK_DEFINITION: rentdaddy-app

jobs:
  test:
    name: Run Tests
    if: ${{ github.event.inputs.skip_tests != 'true' }}
    uses: ./.github/workflows/ci.yml
    secrets: inherit

  terraform:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    needs: [test]
    if: |
      always() && 
      (needs.test.result == 'success' || github.event.inputs.skip_tests == 'true') &&
      github.event.inputs.skip_terraform != 'true'
    environment: production
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.5.0"
      
      - name: Terraform Init
        working-directory: ./deployment/simplified_terraform
        run: |
          # Use the GitHub Actions specific Terraform file
          mv main.tf main-local.tf.backup || true
          mv main-github-actions.tf main.tf
          terraform init
      
      - name: Import Existing Resources
        working-directory: ./deployment/simplified_terraform
        run: |
          echo "Checking for existing resources that need to be imported..."
          
          # Function to check and import resource
          check_and_import() {
            local resource_type=$1
            local resource_name=$2
            local resource_id=$3
            local check_command=$4
            
            # Check if resource exists in state
            if ! terraform state show "${resource_type}.${resource_name}" &>/dev/null; then
              # Check if resource exists in AWS
              if eval "$check_command" &>/dev/null; then
                echo "Importing ${resource_type}.${resource_name}..."
                terraform import -var="aws_account_id=${{ env.AWS_ACCOUNT_ID }}" "${resource_type}.${resource_name}" "$resource_id" || true
              fi
            fi
          }
          
          # Import ALB if it exists
          ALB_ARN=$(aws elbv2 describe-load-balancers --names rentdaddy-alb --query 'LoadBalancers[0].LoadBalancerArn' --output text 2>/dev/null || echo "")
          if [ "$ALB_ARN" != "" ] && [ "$ALB_ARN" != "None" ]; then
            check_and_import "aws_lb" "main" "$ALB_ARN" "aws elbv2 describe-load-balancers --names rentdaddy-alb"
          fi
          
          # Import Target Groups
          BACKEND_TG_ARN=$(aws elbv2 describe-target-groups --names backend-tg --query 'TargetGroups[0].TargetGroupArn' --output text 2>/dev/null || echo "")
          if [ "$BACKEND_TG_ARN" != "" ] && [ "$BACKEND_TG_ARN" != "None" ]; then
            check_and_import "aws_lb_target_group" "backend" "$BACKEND_TG_ARN" "aws elbv2 describe-target-groups --names backend-tg"
          fi
          
          DOCUMENSO_TG_ARN=$(aws elbv2 describe-target-groups --names documenso-tg --query 'TargetGroups[0].TargetGroupArn' --output text 2>/dev/null || echo "")
          if [ "$DOCUMENSO_TG_ARN" != "" ] && [ "$DOCUMENSO_TG_ARN" != "None" ]; then
            check_and_import "aws_lb_target_group" "documenso" "$DOCUMENSO_TG_ARN" "aws elbv2 describe-target-groups --names documenso-tg"
          fi
          
          # Import ECS Cluster
          check_and_import "aws_ecs_cluster" "main" "rentdaddy-cluster" "aws ecs describe-clusters --clusters rentdaddy-cluster --query 'clusters[0]'"
          
          # Import VPC (check for existing VPC first)
          VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=rentdaddy-vpc" --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "")
          if [ "$VPC_ID" != "" ] && [ "$VPC_ID" != "None" ]; then
            check_and_import "aws_vpc" "main" "$VPC_ID" "aws ec2 describe-vpcs --vpc-ids $VPC_ID"
          fi
          
          # Import IAM Roles
          check_and_import "aws_iam_role" "ecs_task_execution" "rentdaddy-ecs-task-execution-role" "aws iam get-role --role-name rentdaddy-ecs-task-execution-role"
          check_and_import "aws_iam_role" "ecs_task" "rentdaddy-ecs-task-role" "aws iam get-role --role-name rentdaddy-ecs-task-role"
          check_and_import "aws_iam_role" "ecs_instance" "rentdaddy-ecs-instance-role" "aws iam get-role --role-name rentdaddy-ecs-instance-role"
          
          # Import CloudWatch Log Groups
          check_and_import "aws_cloudwatch_log_group" "backend_logs" "/ecs/rentdaddy-backend" "aws logs describe-log-groups --log-group-name-prefix /ecs/rentdaddy-backend --query \"logGroups[?logGroupName=='/ecs/rentdaddy-backend']\""
          check_and_import "aws_cloudwatch_log_group" "frontend_logs" "/ecs/rentdaddy-frontend" "aws logs describe-log-groups --log-group-name-prefix /ecs/rentdaddy-frontend --query \"logGroups[?logGroupName=='/ecs/rentdaddy-frontend']\""
          check_and_import "aws_cloudwatch_log_group" "documenso_logs" "/ecs/rentdaddy-documenso" "aws logs describe-log-groups --log-group-name-prefix /ecs/rentdaddy-documenso --query \"logGroups[?logGroupName=='/ecs/rentdaddy-documenso']\""
          
          # Import S3 Bucket
          check_and_import "aws_s3_bucket" "certificates" "rentdaddy-certificates" "aws s3 ls s3://rentdaddy-certificates"
          
          echo "Import check complete"

      # --- Targeted apply for ACM certificate only ---
      - name: Terraform Apply ACM Certificate
        working-directory: ./deployment/simplified_terraform
        run: |
          terraform apply -target=aws_acm_certificate.main -auto-approve \
            -var="aws_account_id=${{ env.AWS_ACCOUNT_ID }}"

      # --- Wait for ACM certificate to be issued before proceeding ---
      - name: Wait for ACM Certificate Validation
        working-directory: ./deployment/simplified_terraform
        run: |
          CERT_ARN=$(terraform output -raw acm_certificate_arn || echo "")
          if [ -z "$CERT_ARN" ]; then
            echo "ACM certificate ARN not found in outputs. Skipping wait."
            exit 1
          fi
          echo "Waiting for ACM certificate to be issued..."
          for i in {1..30}; do
            STATUS=$(aws acm describe-certificate --certificate-arn "$CERT_ARN" --region ${{ env.AWS_REGION }} --query 'Certificate.Status' --output text)
            echo "Current status: $STATUS"
            if [ "$STATUS" = "ISSUED" ]; then
              echo "ACM certificate is issued."
              break
            fi
            if [ "$STATUS" = "FAILED" ]; then
              echo "ACM certificate validation failed."
              exit 1
            fi
            sleep 10
          done

      - name: Terraform Plan
        working-directory: ./deployment/simplified_terraform
        run: |
          terraform plan \
            -var="aws_account_id=${{ env.AWS_ACCOUNT_ID }}" \
            -out=tfplan

      - name: Terraform Apply
        working-directory: ./deployment/simplified_terraform
        if: github.event_name == 'push' || github.event.inputs.deploy == 'true'
        run: |
          terraform apply -auto-approve tfplan


  build-and-deploy:
    name: Build and Deploy Applications
    runs-on: ubuntu-latest
    needs: [test, terraform]
    if: |
      always() && 
      (needs.test.result == 'success' || github.event.inputs.skip_tests == 'true') &&
      (needs.terraform.result == 'success' || needs.terraform.result == 'skipped')
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Create production env files
        run: |
          # Backend env file
          cat > ./backend/backend.env.production.local << EOF
          POSTGRES_HOST=${{ secrets.POSTGRES_HOST }}
          POSTGRES_PORT=${{ secrets.POSTGRES_PORT }}
          POSTGRES_USER=${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_DB=${{ secrets.POSTGRES_DB }}
          PG_URL=${{ secrets.PG_URL }}
          CLERK_SECRET_KEY=${{ secrets.CLERK_SECRET_KEY }}
          CLERK_WEBHOOK=${{ secrets.CLERK_WEBHOOK }}
          SMTP_HOST=${{ secrets.SMTP_HOST }}
          SMTP_PORT=${{ secrets.SMTP_PORT }}
          SMTP_USER=${{ secrets.SMTP_USER }}
          SMTP_PASSWORD=${{ secrets.SMTP_PASSWORD }}
          SMTP_FROM=${{ secrets.SMTP_FROM }}
          SMTP_USE_TLS=${{ secrets.SMTP_USE_TLS }}
          DOCUMENSO_API_KEY=${{ secrets.DOCUMENSO_API_KEY }}
          DOCUMENSO_WEBHOOK_SECRET=${{ secrets.DOCUMENSO_WEBHOOK_SECRET }}
          DOCUMENSO_API_URL=${{ secrets.DOCUMENSO_API_URL }}
          OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          CRON_SECRET_TOKEN=${{ secrets.CRON_SECRET_TOKEN }}
          DOMAIN_URL=${{ secrets.DOMAIN_URL }}
          PORT=8080
          EOF
          
          # Frontend env file
          cat > ./frontend/app/frontend.env.production.local << EOF
          VITE_CLERK_PUBLISHABLE_KEY=${{ secrets.VITE_CLERK_PUBLISHABLE_KEY }}
          VITE_BACKEND_URL=${{ secrets.VITE_BACKEND_URL }}
          VITE_SERVER_URL=${{ secrets.VITE_SERVER_URL }}
          VITE_DOCUMENSO_PUBLIC_URL=${{ secrets.VITE_DOCUMENSO_PUBLIC_URL }}
          VITE_ENV=production
          EOF

      - name: Build, tag, and push images to Amazon ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          # Build and push backend
          docker buildx build \
            --platform linux/amd64 \
            --push \
            -t $ECR_REGISTRY/${{ env.ECR_REPOSITORY_BACKEND }}:$IMAGE_TAG \
            -t $ECR_REGISTRY/${{ env.ECR_REPOSITORY_BACKEND }}:latest \
            -f ./backend/Dockerfile.prod \
            ./backend
          
          # Build and push frontend
          docker buildx build \
            --platform linux/amd64 \
            --push \
            -t $ECR_REGISTRY/${{ env.ECR_REPOSITORY_FRONTEND }}:$IMAGE_TAG \
            -t $ECR_REGISTRY/${{ env.ECR_REPOSITORY_FRONTEND }}:latest \
            -f ./frontend/app/Dockerfile.prod \
            ./frontend/app

      - name: Download current task definition
        run: |
          aws ecs describe-task-definition \
            --task-definition ${{ env.ECS_TASK_DEFINITION }} \
            --query taskDefinition > task-definition.json

      - name: Update task definition with new images
        id: task-def
        run: |
          # Remove fields that are not valid for register-task-definition
          # and update both container images in the task definition
          jq 'del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, .registeredAt, .registeredBy) | 
              .containerDefinitions[0].image = "'$ECR_REGISTRY'/'$ECR_REPOSITORY_BACKEND':'$IMAGE_TAG'" | 
              .containerDefinitions[1].image = "'$ECR_REGISTRY'/'$ECR_REPOSITORY_FRONTEND':'$IMAGE_TAG'"' \
              task-definition.json > new-task-definition.json
          echo "task-definition=new-task-definition.json" >> $GITHUB_OUTPUT

      - name: Check ECS Agent Connectivity
        run: |
          # Check if all ECS agents are connected
          echo "Checking ECS container instance health..."
          
          # Get all container instances
          CONTAINER_INSTANCES=$(aws ecs list-container-instances \
            --cluster ${{ env.ECS_CLUSTER }} \
            --query 'containerInstanceArns[]' \
            --output text)
          
          if [ -z "$CONTAINER_INSTANCES" ]; then
            echo "Error: No container instances found in cluster"
            exit 1
          fi
          
          # Check each instance for agent connectivity
          DISCONNECTED_COUNT=0
          for INSTANCE_ARN in $CONTAINER_INSTANCES; do
            AGENT_CONNECTED=$(aws ecs describe-container-instances \
              --cluster ${{ env.ECS_CLUSTER }} \
              --container-instances $INSTANCE_ARN \
              --query 'containerInstances[0].agentConnected' \
              --output text)
            
            if [ "$AGENT_CONNECTED" != "true" ]; then
              EC2_INSTANCE_ID=$(aws ecs describe-container-instances \
                --cluster ${{ env.ECS_CLUSTER }} \
                --container-instances $INSTANCE_ARN \
                --query 'containerInstances[0].ec2InstanceId' \
                --output text)
              echo "Warning: ECS agent disconnected on instance $EC2_INSTANCE_ID"
              ((DISCONNECTED_COUNT++))
            fi
          done
          
          if [ $DISCONNECTED_COUNT -gt 0 ]; then
            echo "Error: $DISCONNECTED_COUNT ECS agent(s) are disconnected"
            echo "Please run the following script to fix: deployment/scripts/check_and_fix_ecs_agent.sh"
            exit 1
          fi
          
          echo "✓ All ECS agents are connected"

      - name: Deploy Amazon ECS task definition
        timeout-minutes: 15
        run: |
          # Register new task definition
          NEW_TASK_DEF_ARN=$(aws ecs register-task-definition \
            --cli-input-json file://new-task-definition.json \
            --query 'taskDefinition.taskDefinitionArn' \
            --output text)
          
          echo "New task definition registered: $NEW_TASK_DEF_ARN"
          
          # Update service
          aws ecs update-service \
            --cluster ${{ env.ECS_CLUSTER }} \
            --service ${{ env.ECS_SERVICE }} \
            --task-definition $NEW_TASK_DEF_ARN \
            --force-new-deployment
          
          echo "Service update initiated. Waiting for deployment..."
          
          # Wait for service stability with better error handling
          DEPLOYMENT_TIMEOUT=900  # 15 minutes
          DEPLOYMENT_CHECK_INTERVAL=30  # Check every 30 seconds
          ELAPSED_TIME=0
          
          while [ $ELAPSED_TIME -lt $DEPLOYMENT_TIMEOUT ]; do
            # Get deployment status
            DEPLOYMENT_STATUS=$(aws ecs describe-services \
              --cluster ${{ env.ECS_CLUSTER }} \
              --services ${{ env.ECS_SERVICE }} \
              --query 'services[0].deployments[?status==`PRIMARY`].rolloutState' \
              --output text)
            
            if [ "$DEPLOYMENT_STATUS" == "COMPLETED" ]; then
              echo "✓ Deployment completed successfully!"
              break
            elif [ "$DEPLOYMENT_STATUS" == "FAILED" ]; then
              echo "✗ Deployment failed!"
              aws ecs describe-services \
                --cluster ${{ env.ECS_CLUSTER }} \
                --services ${{ env.ECS_SERVICE }} \
                --query 'services[0].events[:5]'
              exit 1
            else
              echo "Deployment status: $DEPLOYMENT_STATUS (elapsed: ${ELAPSED_TIME}s)"
              
              # Check for placement failures
              FAILED_TASKS=$(aws ecs describe-services \
                --cluster ${{ env.ECS_CLUSTER }} \
                --services ${{ env.ECS_SERVICE }} \
                --query 'services[0].deployments[?status==`PRIMARY`].failedTasks' \
                --output text)
              
              if [ "$FAILED_TASKS" -gt 5 ]; then
                echo "Warning: $FAILED_TASKS failed task attempts"
                echo "Recent events:"
                aws ecs describe-services \
                  --cluster ${{ env.ECS_CLUSTER }} \
                  --services ${{ env.ECS_SERVICE }} \
                  --query 'services[0].events[:3]'
              fi
              
              sleep $DEPLOYMENT_CHECK_INTERVAL
              ((ELAPSED_TIME+=DEPLOYMENT_CHECK_INTERVAL))
            fi
          done
          
          if [ $ELAPSED_TIME -ge $DEPLOYMENT_TIMEOUT ]; then
            echo "Deployment timed out after ${DEPLOYMENT_TIMEOUT} seconds"
            echo "Final deployment status:"
            aws ecs describe-services \
              --cluster ${{ env.ECS_CLUSTER }} \
              --services ${{ env.ECS_SERVICE }} \
              --query 'services[0].deployments'
            exit 1
          fi

      - name: Verify Deployment
        run: |
          echo "Checking service health..."
          
          # Check frontend
          response=$(curl -s -o /dev/null -w "%{http_code}" https://app.curiousdev.net -m 10)
          if [ "$response" != "200" ]; then
            echo "Frontend health check failed with status $response"
            exit 1
          fi
          echo "✅ Frontend is healthy"
          
          # Check API
          response=$(curl -s -o /dev/null -w "%{http_code}" https://api.curiousdev.net/healthz -m 10)
          if [ "$response" != "200" ]; then
            echo "API health check failed with status $response"
            exit 1
          fi
          echo "✅ API is healthy"
          
          # Check Documenso (expecting 307 redirect)
          response=$(curl -s -o /dev/null -w "%{http_code}" https://docs.curiousdev.net -m 10)
          if [[ "$response" != "3"* ]]; then
            echo "Documenso health check failed with status $response"
            exit 1
          fi
          echo "✅ Documenso is healthy"

  update-documenso-cert:
    name: Update Documenso Certificate
    runs-on: ubuntu-latest
    needs: [build-and-deploy]
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Check if certificate exists
        run: |
          if [ -f "./certs/cert.p12" ]; then
            echo "CERT_EXISTS=true" >> $GITHUB_ENV
          else
            echo "CERT_EXISTS=false" >> $GITHUB_ENV
          fi

      - name: Upload certificate to S3
        if: env.CERT_EXISTS == 'true'
        run: |
          aws s3 cp ./certs/cert.p12 s3://rentdaddy-certificates/documenso/cert.p12 \
            --server-side-encryption AES256

      - name: Update ECS service to use new certificate
        if: env.CERT_EXISTS == 'true'
        run: |
          echo "Certificate update process would run here"
          # This would typically involve updating the task definition
          # to mount the certificate from S3 or EFS